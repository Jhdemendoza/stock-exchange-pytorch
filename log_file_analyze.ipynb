{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_by_threshold(thresholds):\n",
    "    files = sorted(os.listdir('logs/'))\n",
    "    \n",
    "    by_threshold = []\n",
    "    for threshold in thresholds:\n",
    "        by_threshold += [[file for file in files if threshold in file.split('_')[-1]]]\n",
    "    return by_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_key(original_line):\n",
    "    result = []\n",
    "    of_interest = ['block_depth', \n",
    "                   'const_factor', \n",
    "                   'learning_rate', \n",
    "                   'linear_dim', \n",
    "                   'percentile']\n",
    "    for item in of_interest:\n",
    "        pattern = re.compile(item+'=[\\d.]*')\n",
    "        result += [re.search(pattern, original_line).group(0)]\n",
    "    return ','.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_log_file(file_path):\n",
    "    split_colon = lambda x: x.split(':')\n",
    "\n",
    "    test_data = (pd.read_csv(file_path)\n",
    "                   .iloc[:-1, 2:]\n",
    "                   .iloc[1::2]\n",
    "                   .iloc[:, 1:8]\n",
    "                   .applymap(split_colon))\n",
    "    \n",
    "    if test_data.empty:\n",
    "        return None\n",
    "    \n",
    "    names = (test_data.applymap(lambda x: x[0])\n",
    "                      .iloc[0]\n",
    "                      .values\n",
    "                      .tolist())\n",
    "    names = list(map(lambda x: x.replace(' ', ''), names))\n",
    "    dataframe = (test_data.applymap(lambda x: float(x[-1]))\n",
    "                     .copy())\n",
    "    dataframe.columns = names\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_and_df(file_name):\n",
    "    file_path = 'logs/' + file_name\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        line = f.readlines()[0]\n",
    "        key = create_key(line)\n",
    "    \n",
    "    df = process_single_log_file(file_path)\n",
    "    \n",
    "    if df is None:\n",
    "        return None, None\n",
    "    else:\n",
    "        return key, df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_key_df(file_name):\n",
    "    key, df = get_key_and_df(file_name)\n",
    "    if df is None:\n",
    "        return None, None\n",
    "    \n",
    "    relevant_df = df[df.F1Score > 0.05].copy()\n",
    "    if len(relevant_df) > 0:\n",
    "        return key, relevant_df\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def garner_relevant_dictionary():\n",
    "    \n",
    "    thresholds = ['0.1', '0.2', '0.3', '0.35', '0.65', '0.7', '0.8', '0.9']\n",
    "    files_by_thresholds = agg_by_threshold(thresholds)\n",
    "\n",
    "    # Not sure if this should be default_dict\n",
    "    so_far = defaultdict(list)\n",
    "    for files in files_by_thresholds:\n",
    "        for file in files:\n",
    "            key, df = get_relevant_key_df(file)\n",
    "            if key is not None:\n",
    "                so_far[key].append(df)\n",
    "    \n",
    "    return so_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = garner_relevant_dictionary()\n",
    "# iter_my_dict = iter(my_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_results = []\n",
    "pct = 0.8\n",
    "statement = 'percentile={}'.format(pct)\n",
    "for key, df in my_dict.items():\n",
    "    if statement in key : # and 'block_depth=3' in key:\n",
    "        training_results.append((key, df[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_results_sorted = sorted(training_results, \n",
    "#                                  key=lambda x: (x[1].Mean*x[1].F1Score).mean(), \n",
    "#                                  reverse=True)\n",
    "reverse = pct > 0.5\n",
    "\n",
    "training_results_sorted = sorted(training_results, \n",
    "                                 key=lambda x: (x[1].Mean).mean(), \n",
    "                                 reverse=reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_depth=5,const_factor=8,learning_rate=0.007,linear_dim=3,percentile=0.8\n",
      "block_depth=3,const_factor=8,learning_rate=0.01,linear_dim=2,percentile=0.8\n",
      "block_depth=5,const_factor=8,learning_rate=0.007,linear_dim=5,percentile=0.8\n",
      "block_depth=3,const_factor=8,learning_rate=0.007,linear_dim=5,percentile=0.85\n",
      "block_depth=5,const_factor=8,learning_rate=0.007,linear_dim=5,percentile=0.85\n",
      "block_depth=3,const_factor=8,learning_rate=0.007,linear_dim=3,percentile=0.8\n",
      "block_depth=5,const_factor=8,learning_rate=0.007,linear_dim=6,percentile=0.85\n",
      "block_depth=3,const_factor=16,learning_rate=0.007,linear_dim=6,percentile=0.85\n",
      "block_depth=3,const_factor=8,learning_rate=0.007,linear_dim=6,percentile=0.85\n",
      "block_depth=6,const_factor=4,learning_rate=0.007,linear_dim=5,percentile=0.85\n",
      "block_depth=3,const_factor=2,learning_rate=0.007,linear_dim=2,percentile=0.8\n",
      "block_depth=6,const_factor=4,learning_rate=0.007,linear_dim=3,percentile=0.85\n",
      "block_depth=3,const_factor=8,learning_rate=0.007,linear_dim=3,percentile=0.85\n",
      "block_depth=5,const_factor=8,learning_rate=0.007,linear_dim=3,percentile=0.85\n",
      "block_depth=3,const_factor=16,learning_rate=0.007,linear_dim=5,percentile=0.85\n",
      "block_depth=6,const_factor=6,learning_rate=0.007,linear_dim=3,percentile=0.8\n",
      "block_depth=6,const_factor=6,learning_rate=0.007,linear_dim=4,percentile=0.8\n",
      "block_depth=3,const_factor=16,learning_rate=0.007,linear_dim=3,percentile=0.8\n",
      "block_depth=3,const_factor=16,learning_rate=0.007,linear_dim=3,percentile=0.85\n",
      "block_depth=3,const_factor=2,learning_rate=0.007,linear_dim=4,percentile=0.8\n",
      "block_depth=4,const_factor=2,learning_rate=0.007,linear_dim=3,percentile=0.8\n",
      "block_depth=6,const_factor=8,learning_rate=0.007,linear_dim=4,percentile=0.8\n",
      "block_depth=3,const_factor=4,learning_rate=0.007,linear_dim=3,percentile=0.8\n",
      "block_depth=6,const_factor=4,learning_rate=0.007,linear_dim=4,percentile=0.8\n",
      "block_depth=3,const_factor=8,learning_rate=0.01,linear_dim=4,percentile=0.8\n",
      "block_depth=3,const_factor=16,learning_rate=0.007,linear_dim=5,percentile=0.8\n",
      "block_depth=6,const_factor=4,learning_rate=0.007,linear_dim=5,percentile=0.8\n",
      "block_depth=3,const_factor=4,learning_rate=0.007,linear_dim=2,percentile=0.8\n",
      "block_depth=5,const_factor=4,learning_rate=0.007,linear_dim=4,percentile=0.8\n",
      "block_depth=6,const_factor=6,learning_rate=0.007,linear_dim=3,percentile=0.85\n",
      "block_depth=6,const_factor=4,learning_rate=0.007,linear_dim=4,percentile=0.85\n",
      "block_depth=5,const_factor=2,learning_rate=0.007,linear_dim=4,percentile=0.8\n",
      "block_depth=5,const_factor=8,learning_rate=0.007,linear_dim=6,percentile=0.8\n",
      "block_depth=6,const_factor=8,learning_rate=0.007,linear_dim=5,percentile=0.8\n",
      "block_depth=6,const_factor=4,learning_rate=0.007,linear_dim=3,percentile=0.8\n",
      "block_depth=4,const_factor=4,learning_rate=0.007,linear_dim=2,percentile=0.8\n",
      "block_depth=3,const_factor=4,learning_rate=0.007,linear_dim=4,percentile=0.8\n",
      "block_depth=5,const_factor=4,learning_rate=0.007,linear_dim=3,percentile=0.8\n",
      "block_depth=3,const_factor=8,learning_rate=0.007,linear_dim=6,percentile=0.8\n",
      "block_depth=3,const_factor=2,learning_rate=0.007,linear_dim=3,percentile=0.8\n",
      "block_depth=3,const_factor=8,learning_rate=0.007,linear_dim=5,percentile=0.8\n",
      "block_depth=4,const_factor=2,learning_rate=0.007,linear_dim=2,percentile=0.8\n",
      "block_depth=6,const_factor=8,learning_rate=0.007,linear_dim=6,percentile=0.85\n",
      "block_depth=4,const_factor=4,learning_rate=0.007,linear_dim=4,percentile=0.8\n",
      "block_depth=4,const_factor=4,learning_rate=0.007,linear_dim=3,percentile=0.8\n",
      "block_depth=3,const_factor=8,learning_rate=0.01,linear_dim=3,percentile=0.8\n",
      "block_depth=4,const_factor=2,learning_rate=0.007,linear_dim=4,percentile=0.8\n",
      "block_depth=5,const_factor=2,learning_rate=0.007,linear_dim=3,percentile=0.8\n",
      "block_depth=3,const_factor=16,learning_rate=0.007,linear_dim=6,percentile=0.8\n",
      "block_depth=5,const_factor=2,learning_rate=0.007,linear_dim=2,percentile=0.8\n",
      "block_depth=6,const_factor=8,learning_rate=0.007,linear_dim=6,percentile=0.8\n",
      "block_depth=6,const_factor=8,learning_rate=0.007,linear_dim=4,percentile=0.85\n",
      "block_depth=6,const_factor=8,learning_rate=0.007,linear_dim=8,percentile=0.85\n",
      "block_depth=6,const_factor=8,learning_rate=0.007,linear_dim=8,percentile=0.8\n",
      "block_depth=5,const_factor=4,learning_rate=0.007,linear_dim=2,percentile=0.8\n",
      "block_depth=6,const_factor=8,learning_rate=0.007,linear_dim=5,percentile=0.85\n"
     ]
    }
   ],
   "source": [
    "for key, result in training_results_sorted:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1Score, Mean, Precision, Count\n",
      "0.17922, 0.01338, 0.39327, 30\n",
      "0.22208, 0.01149, 0.37211, 19\n",
      "0.24413, 0.01102, 0.34047, 29\n",
      "0.16932, 0.01080, 0.26266, 28\n",
      "0.12625, 0.01028, 0.28027, 26\n",
      "0.16053, 0.00990, 0.33468, 28\n",
      "0.12834, 0.00972, 0.26941, 28\n",
      "0.10877, 0.00963, 0.29102, 24\n",
      "0.11362, 0.00918, 0.24601, 29\n",
      "0.12926, 0.00891, 0.23334, 24\n",
      "0.14407, 0.00890, 0.34747, 24\n",
      "0.12807, 0.00889, 0.25183, 25\n",
      "0.09826, 0.00886, 0.26536, 26\n",
      "0.11461, 0.00883, 0.26455, 25\n",
      "0.15034, 0.00836, 0.29979, 26\n",
      "0.18125, 0.00835, 0.33398, 29\n",
      "0.19071, 0.00819, 0.32979, 22\n",
      "0.17758, 0.00801, 0.34084, 28\n",
      "0.08482, 0.00764, 0.28134, 22\n",
      "0.16853, 0.00739, 0.31126, 27\n",
      "0.19617, 0.00719, 0.32692, 25\n",
      "0.18793, 0.00712, 0.31359, 29\n",
      "0.12554, 0.00703, 0.32067, 28\n",
      "0.19330, 0.00694, 0.30793, 29\n",
      "0.20437, 0.00669, 0.29850, 18\n",
      "0.15242, 0.00666, 0.31667, 30\n",
      "0.17367, 0.00652, 0.30034, 28\n",
      "0.19241, 0.00638, 0.33580, 27\n",
      "0.19568, 0.00603, 0.31015, 28\n",
      "0.11825, 0.00601, 0.26624, 24\n",
      "0.15309, 0.00585, 0.25472, 25\n",
      "0.16789, 0.00580, 0.27878, 29\n",
      "0.15554, 0.00562, 0.29463, 30\n",
      "0.16125, 0.00551, 0.28984, 30\n",
      "0.18682, 0.00532, 0.29996, 24\n",
      "0.19383, 0.00508, 0.30739, 29\n",
      "0.16869, 0.00489, 0.30820, 27\n",
      "0.12960, 0.00456, 0.30538, 28\n",
      "0.16220, 0.00425, 0.29691, 26\n",
      "0.16126, 0.00416, 0.30876, 24\n",
      "0.14044, 0.00405, 0.27573, 28\n",
      "0.17761, 0.00364, 0.31441, 23\n",
      "0.12703, 0.00312, 0.23569, 26\n",
      "0.17847, 0.00307, 0.27981, 28\n",
      "0.18403, 0.00303, 0.28542, 26\n",
      "0.16112, 0.00301, 0.28353, 19\n",
      "0.17231, 0.00273, 0.28209, 27\n",
      "0.20173, 0.00255, 0.29469, 26\n",
      "0.14279, 0.00255, 0.27398, 28\n",
      "0.12146, 0.00233, 0.28066, 25\n",
      "0.14463, 0.00225, 0.26142, 29\n",
      "0.10729, 0.00138, 0.23362, 23\n",
      "0.10498, 0.00094, 0.19623, 25\n",
      "0.15479, 0.00073, 0.25112, 28\n",
      "0.16481, 0.00070, 0.28226, 25\n",
      "0.10477, -0.00462, 0.19264, 23\n"
     ]
    }
   ],
   "source": [
    "print('F1Score, Mean, Precision, Count')\n",
    "for key, result in training_results_sorted:\n",
    "    print('{:.5f}, {:.5f}, {:.5f}, {}'.format(\n",
    "          result.F1Score.mean(), \n",
    "          result.Mean.mean(), \n",
    "          result.Precision.mean(), \n",
    "          result.Mean.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_depth=5,const_factor=8,learning_rate=0.007,linear_dim=5,percentile=0.85\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BCE</th>\n",
       "      <th>F1Score</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Stdev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.42354</td>\n",
       "      <td>0.06412</td>\n",
       "      <td>0.58594</td>\n",
       "      <td>0.54730</td>\n",
       "      <td>0.03405</td>\n",
       "      <td>0.02624</td>\n",
       "      <td>0.03656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.42820</td>\n",
       "      <td>0.05445</td>\n",
       "      <td>0.58305</td>\n",
       "      <td>0.42988</td>\n",
       "      <td>0.02907</td>\n",
       "      <td>0.02012</td>\n",
       "      <td>0.03243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.43975</td>\n",
       "      <td>0.07715</td>\n",
       "      <td>0.57452</td>\n",
       "      <td>0.38641</td>\n",
       "      <td>0.04285</td>\n",
       "      <td>0.01757</td>\n",
       "      <td>0.03396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.45820</td>\n",
       "      <td>0.13460</td>\n",
       "      <td>0.57209</td>\n",
       "      <td>0.29990</td>\n",
       "      <td>0.08677</td>\n",
       "      <td>0.01170</td>\n",
       "      <td>0.03480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.47012</td>\n",
       "      <td>0.11354</td>\n",
       "      <td>0.56182</td>\n",
       "      <td>0.29395</td>\n",
       "      <td>0.07036</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.03495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.46491</td>\n",
       "      <td>0.14713</td>\n",
       "      <td>0.57156</td>\n",
       "      <td>0.29655</td>\n",
       "      <td>0.09784</td>\n",
       "      <td>0.01170</td>\n",
       "      <td>0.03414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.46986</td>\n",
       "      <td>0.10516</td>\n",
       "      <td>0.56300</td>\n",
       "      <td>0.29926</td>\n",
       "      <td>0.06378</td>\n",
       "      <td>0.01204</td>\n",
       "      <td>0.03515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.49435</td>\n",
       "      <td>0.11795</td>\n",
       "      <td>0.55239</td>\n",
       "      <td>0.23981</td>\n",
       "      <td>0.07821</td>\n",
       "      <td>0.00723</td>\n",
       "      <td>0.03515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.47911</td>\n",
       "      <td>0.09836</td>\n",
       "      <td>0.55442</td>\n",
       "      <td>0.26185</td>\n",
       "      <td>0.06055</td>\n",
       "      <td>0.00914</td>\n",
       "      <td>0.03481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.49411</td>\n",
       "      <td>0.15324</td>\n",
       "      <td>0.56459</td>\n",
       "      <td>0.25860</td>\n",
       "      <td>0.10888</td>\n",
       "      <td>0.00949</td>\n",
       "      <td>0.03562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.49878</td>\n",
       "      <td>0.12555</td>\n",
       "      <td>0.55754</td>\n",
       "      <td>0.25610</td>\n",
       "      <td>0.08315</td>\n",
       "      <td>0.00980</td>\n",
       "      <td>0.03569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.50482</td>\n",
       "      <td>0.14634</td>\n",
       "      <td>0.55599</td>\n",
       "      <td>0.25266</td>\n",
       "      <td>0.10300</td>\n",
       "      <td>0.00832</td>\n",
       "      <td>0.03729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.50815</td>\n",
       "      <td>0.13028</td>\n",
       "      <td>0.55280</td>\n",
       "      <td>0.24857</td>\n",
       "      <td>0.08827</td>\n",
       "      <td>0.00839</td>\n",
       "      <td>0.03654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.50398</td>\n",
       "      <td>0.12514</td>\n",
       "      <td>0.56126</td>\n",
       "      <td>0.26608</td>\n",
       "      <td>0.08181</td>\n",
       "      <td>0.01033</td>\n",
       "      <td>0.03655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.51042</td>\n",
       "      <td>0.12783</td>\n",
       "      <td>0.55361</td>\n",
       "      <td>0.25653</td>\n",
       "      <td>0.08512</td>\n",
       "      <td>0.00867</td>\n",
       "      <td>0.03697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.51281</td>\n",
       "      <td>0.13244</td>\n",
       "      <td>0.55383</td>\n",
       "      <td>0.24844</td>\n",
       "      <td>0.09028</td>\n",
       "      <td>0.00729</td>\n",
       "      <td>0.03823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.51374</td>\n",
       "      <td>0.12706</td>\n",
       "      <td>0.55751</td>\n",
       "      <td>0.25811</td>\n",
       "      <td>0.08427</td>\n",
       "      <td>0.00852</td>\n",
       "      <td>0.03813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.51140</td>\n",
       "      <td>0.11071</td>\n",
       "      <td>0.55228</td>\n",
       "      <td>0.25482</td>\n",
       "      <td>0.07072</td>\n",
       "      <td>0.00870</td>\n",
       "      <td>0.03851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.51534</td>\n",
       "      <td>0.13672</td>\n",
       "      <td>0.55522</td>\n",
       "      <td>0.25056</td>\n",
       "      <td>0.09401</td>\n",
       "      <td>0.00844</td>\n",
       "      <td>0.03811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.52477</td>\n",
       "      <td>0.14563</td>\n",
       "      <td>0.55499</td>\n",
       "      <td>0.23983</td>\n",
       "      <td>0.10456</td>\n",
       "      <td>0.00719</td>\n",
       "      <td>0.03925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.53693</td>\n",
       "      <td>0.15845</td>\n",
       "      <td>0.55353</td>\n",
       "      <td>0.23416</td>\n",
       "      <td>0.11973</td>\n",
       "      <td>0.00727</td>\n",
       "      <td>0.03918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.53996</td>\n",
       "      <td>0.13762</td>\n",
       "      <td>0.55011</td>\n",
       "      <td>0.23844</td>\n",
       "      <td>0.09673</td>\n",
       "      <td>0.00728</td>\n",
       "      <td>0.03893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.53209</td>\n",
       "      <td>0.15376</td>\n",
       "      <td>0.55622</td>\n",
       "      <td>0.24431</td>\n",
       "      <td>0.11218</td>\n",
       "      <td>0.00773</td>\n",
       "      <td>0.03929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.53681</td>\n",
       "      <td>0.14956</td>\n",
       "      <td>0.55418</td>\n",
       "      <td>0.24353</td>\n",
       "      <td>0.10792</td>\n",
       "      <td>0.00780</td>\n",
       "      <td>0.03909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.54136</td>\n",
       "      <td>0.15616</td>\n",
       "      <td>0.55569</td>\n",
       "      <td>0.24252</td>\n",
       "      <td>0.11515</td>\n",
       "      <td>0.00777</td>\n",
       "      <td>0.03996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.53874</td>\n",
       "      <td>0.15366</td>\n",
       "      <td>0.55496</td>\n",
       "      <td>0.23889</td>\n",
       "      <td>0.11325</td>\n",
       "      <td>0.00735</td>\n",
       "      <td>0.03939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        BCE  F1Score  ROC_AUC  Precision   Recall     Mean    Stdev\n",
       "13  0.42354  0.06412  0.58594    0.54730  0.03405  0.02624  0.03656\n",
       "15  0.42820  0.05445  0.58305    0.42988  0.02907  0.02012  0.03243\n",
       "17  0.43975  0.07715  0.57452    0.38641  0.04285  0.01757  0.03396\n",
       "19  0.45820  0.13460  0.57209    0.29990  0.08677  0.01170  0.03480\n",
       "21  0.47012  0.11354  0.56182    0.29395  0.07036  0.01109  0.03495\n",
       "23  0.46491  0.14713  0.57156    0.29655  0.09784  0.01170  0.03414\n",
       "25  0.46986  0.10516  0.56300    0.29926  0.06378  0.01204  0.03515\n",
       "27  0.49435  0.11795  0.55239    0.23981  0.07821  0.00723  0.03515\n",
       "29  0.47911  0.09836  0.55442    0.26185  0.06055  0.00914  0.03481\n",
       "31  0.49411  0.15324  0.56459    0.25860  0.10888  0.00949  0.03562\n",
       "33  0.49878  0.12555  0.55754    0.25610  0.08315  0.00980  0.03569\n",
       "35  0.50482  0.14634  0.55599    0.25266  0.10300  0.00832  0.03729\n",
       "37  0.50815  0.13028  0.55280    0.24857  0.08827  0.00839  0.03654\n",
       "39  0.50398  0.12514  0.56126    0.26608  0.08181  0.01033  0.03655\n",
       "41  0.51042  0.12783  0.55361    0.25653  0.08512  0.00867  0.03697\n",
       "43  0.51281  0.13244  0.55383    0.24844  0.09028  0.00729  0.03823\n",
       "45  0.51374  0.12706  0.55751    0.25811  0.08427  0.00852  0.03813\n",
       "47  0.51140  0.11071  0.55228    0.25482  0.07072  0.00870  0.03851\n",
       "49  0.51534  0.13672  0.55522    0.25056  0.09401  0.00844  0.03811\n",
       "51  0.52477  0.14563  0.55499    0.23983  0.10456  0.00719  0.03925\n",
       "53  0.53693  0.15845  0.55353    0.23416  0.11973  0.00727  0.03918\n",
       "55  0.53996  0.13762  0.55011    0.23844  0.09673  0.00728  0.03893\n",
       "57  0.53209  0.15376  0.55622    0.24431  0.11218  0.00773  0.03929\n",
       "59  0.53681  0.14956  0.55418    0.24353  0.10792  0.00780  0.03909\n",
       "61  0.54136  0.15616  0.55569    0.24252  0.11515  0.00777  0.03996\n",
       "63  0.53874  0.15366  0.55496    0.23889  0.11325  0.00735  0.03939"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks = 4\n",
    "print(training_results_sorted[ranks][0])\n",
    "training_results_sorted[ranks][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
