{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['aapl', 'amd', 'msft', 'intc', 'd', 'sbux', 'atvi',\n",
    "          'ibm', 'ual', 'vrsn', 't', 'mcd', 'vz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# # These are the usual ipython objects, including this one you are creating\n",
    "# ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# # Get a sorted list of the objects and their sizes\n",
    "# sorted([(x, sys.getsizeof(globals().get(x))) \n",
    "#         for x in dir() if not x.startswith('_') \n",
    "#         and x not in sys.modules and x not in ipython_vars], \n",
    "#        key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "etf_path = 'iexfinance/Data/ETFs/{}.us.txt'\n",
    "stock_path = 'iexfinance/Data/Stocks/{}.us.txt'\n",
    "\n",
    "def read_csv(ticker, is_etf=False):\n",
    "    path = etf_path.format(ticker) if is_etf else stock_path.format(ticker)\n",
    "    cur_df = pd.read_csv(path)\n",
    "    cur_df.drop(['Volume', \"OpenInt\"], axis=1, inplace=True)\n",
    "    return cur_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy = read_csv('spy', True)\n",
    "spy_default = spy.copy()\n",
    "for ticker in tickers:\n",
    "    ticker_df = read_csv(ticker)\n",
    "    spy_default = pd.merge(spy_default, \n",
    "                           ticker_df, \n",
    "                           on='Date', \n",
    "                           how='left', \n",
    "                           suffixes=('', '_'+ticker))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_delta_historical(df):\n",
    "    original_col = df.columns[1:]\n",
    "    \n",
    "    # shift days\n",
    "    for shift_idx in [3, 5, 10, 20, 40]:\n",
    "        for col in original_col:\n",
    "            df[col+'_'+str(shift_idx)] = df[col].shift(shift_idx)\n",
    "    \n",
    "    # np.log all values\n",
    "    for item in df:\n",
    "        if np.issubdtype(df[item].dtype, np.number):\n",
    "            df[item] = np.log(df[item])\n",
    "    \n",
    "    df_values = df.values\n",
    "    # for lookback\n",
    "    for row_idx in range(5, df_values.shape[1], 4):\n",
    "        df_values[:, row_idx:row_idx+4] = df_values[:, 1:5] - \\\n",
    "                                           df_values[:, row_idx:row_idx+4]\n",
    "    # for today\n",
    "    for idx in range(len(df_values)-1, 0, -1):\n",
    "        df_values[idx, 1:5] -= df_values[idx-1, 1:5]\n",
    "    \n",
    "    return df_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3201, 25) (3201, 5)\n",
      "(3161, 25) (3201, 5)\n"
     ]
    }
   ],
   "source": [
    "spy = read_csv('spy', True)\n",
    "spy_original = read_csv('spy', True)\n",
    "\n",
    "spy_from_fn = give_delta_historical(spy)\n",
    "# x:= revised val, y:= original.shift(-1)\n",
    "print(spy_from_fn.shape, spy_original.shape)\n",
    "# Drop NaN here\n",
    "spy_from_fn = spy_from_fn[40:]\n",
    "print(spy_from_fn.shape, spy_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_output_data(spy_original):\n",
    "    original_columns = spy_original.columns[1:]\n",
    "    # shift 10, 5\n",
    "    for col in original_columns:\n",
    "        spy_original['10_'+str(col)] = spy_original[col].shift(-10)\n",
    "    for col in original_columns:\n",
    "        spy_original['5_'+str(col)] = spy_original[col].shift(-5)\n",
    "    # log_delta\n",
    "    for col in original_columns:\n",
    "        spy_original['10_'+col] = np.log(spy_original['10_'+col].values) - \\\n",
    "                                  np.log(spy_original[col].values)\n",
    "    for col in original_columns:\n",
    "        spy_original['5_'+col] = np.log(spy_original['5_'+col].values) - \\\n",
    "                                 np.log(spy_original[col].values)\n",
    "    return spy_original\n",
    "\n",
    "spy_original = process_output_data(spy_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (3161, 25), Y.shape: (3161,)\n",
      "Indecies of NaN in Y:\n",
      " [[3151]\n",
      " [3152]\n",
      " [3153]\n",
      " [3154]\n",
      " [3155]\n",
      " [3156]\n",
      " [3157]\n",
      " [3158]\n",
      " [3159]\n",
      " [3160]]\n",
      "Drop those rows ...\n",
      "X.shape: (3151, 25), Y.shape: (3151,)\n"
     ]
    }
   ],
   "source": [
    "Y = spy_original['10_Open'][40:]\n",
    "print('X.shape: {}, Y.shape: {}'.format(spy_from_fn.shape, Y.shape))\n",
    "print('Indecies of NaN in Y:\\n {}'.format(np.argwhere(Y.isna())))\n",
    "print('Drop those rows ...')\n",
    "delete_from_back = Y.isna().sum()\n",
    "spy_from_fn = spy_from_fn[:-delete_from_back]\n",
    "Y = Y[:-delete_from_back].values\n",
    "# Y = Y.reshape(-1, 1)\n",
    "print('X.shape: {}, Y.shape: {}'.format(spy_from_fn.shape, Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# astype(..., copy=False)???\n",
    "spy_from_fn[:, 1:] = spy_from_fn[:, 1:].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = pd.DataFrame(spy_from_fn[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sequence data\n",
    "# train_idx, test_idx = train_test_split(np.arange(len(input)))\n",
    "\n",
    "# Sequential data\n",
    "length = int(len(input)* 0.8)\n",
    "train_idx = np.arange(length)\n",
    "test_idx = np.arange(length, len(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2520,) (631,)\n",
      "(2520, 24) (631, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1563, 392)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = input.iloc[train_idx]\n",
    "test_df = input.iloc[test_idx]\n",
    "print(train_idx.shape, test_idx.shape)\n",
    "print(train_df.shape, test_df.shape)\n",
    "# Consider some other y transfroms...\n",
    "y_train = np.where(Y[train_idx]>0, 1, 0)\n",
    "y_test = np.where(Y[test_idx]>0, 1, 0)\n",
    "y_train.sum(), y_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wbaik/.conda/envs/clone_tf/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/wbaik/.conda/envs/clone_tf/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype object were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('Data after standard scaling', StandardScaler(copy=True, with_mean=True, with_std=True)), ('Data after min-max scaling', MinMaxScaler(copy=True, feature_range=(0, 1))), ('Data after max-abs scaling', MaxAbsScaler(copy=True)), ('Data after robust scaling', RobustScaler(copy=True, q...    subsample=100000)), ('Data after sample-wise L2 normalizing', Normalizer(copy=True, norm='l2'))],\n",
       "       transformer_weights=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfomer = [\n",
    "    ('Data after standard scaling',\n",
    "        StandardScaler()),\n",
    "    ('Data after min-max scaling',\n",
    "        MinMaxScaler()),\n",
    "    ('Data after max-abs scaling',\n",
    "        MaxAbsScaler()),\n",
    "    ('Data after robust scaling',\n",
    "        RobustScaler(quantile_range=(25, 75))),\n",
    "    ('Data after power transformation (Yeo-Johnson)',\n",
    "     PowerTransformer(method='yeo-johnson')),\n",
    "    ('Data after quantile transformation (gaussian pdf)',\n",
    "        QuantileTransformer(output_distribution='normal')),\n",
    "    ('Data after quantile transformation (uniform pdf)',\n",
    "        QuantileTransformer(output_distribution='uniform')),\n",
    "    ('Data after sample-wise L2 normalizing',\n",
    "        Normalizer()),\n",
    "]\n",
    "\n",
    "combined = FeatureUnion(transfomer)\n",
    "combined.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wbaik/.conda/envs/clone_tf/lib/python3.6/site-packages/sklearn/pipeline.py:605: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n",
      "/home/wbaik/.conda/envs/clone_tf/lib/python3.6/site-packages/sklearn/pipeline.py:605: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n"
     ]
    }
   ],
   "source": [
    "x_train_transformed = combined.transform(train_df)\n",
    "x_test_transformed = combined.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2520, 192), (631, 192))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_transformed.shape, x_test_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TickerData(Dataset):\n",
    "    def __init__(self, ticker, x, y):\n",
    "        '''\n",
    "        :param ticker: string\n",
    "        :param x: np.array of x\n",
    "        :param y: np.array of y\n",
    "        '''\n",
    "        self.ticker = ticker\n",
    "        self.x = torch.FloatTensor(x)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_shape, final_output_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.c1 = nn.Conv1d(input_shape[0],        final_output_size * 2, (4,), 4)\n",
    "        self.c2 = nn.Conv1d(final_output_size * 2, final_output_size * 1, (1,), 1)\n",
    "        self.c3 = nn.Conv1d(final_output_size * 1, 1,                     (1,), 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.c1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.c2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.c3(x)\n",
    "        return torch.tanh(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_shape, final_output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.c1 = nn.ConvTranspose1d(1,                     \n",
    "                                     final_output_size * 1, (1,), stride=1)\n",
    "        self.c2 = nn.ConvTranspose1d(final_output_size * 1, \n",
    "                                     final_output_size * 2, (1,), 1)\n",
    "        self.c3 = nn.ConvTranspose1d(final_output_size * 2, \n",
    "                                     input_shape[0],        (4,), 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.c1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.c2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.c3(x)\n",
    "        return x\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_shape, final_output_size):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = Encoder(input_shape, final_output_size)\n",
    "        self.decoder = Decoder(input_shape, final_output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_dataset = TickerData('spy', x_train_transformed, y_train)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_dl = DataLoader(spy_dataset, \n",
    "                      num_workers=1, \n",
    "                      batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder((8, 24), 2).cuda()\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import clip_grad_norm_\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "\n",
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 2400, 3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [399/399], loss:0.02226"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "num_epochs=400\n",
    "for epoch in range(num_epochs):\n",
    "    cur_loss = 0.0\n",
    "    for data in train_dl:\n",
    "        x, _ = data\n",
    "        x = x.reshape(-1, 8, 24).cuda()\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, x)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        cur_loss += loss.item()\n",
    "    \n",
    "    losses += [cur_loss]\n",
    "    lr_scheduler.step()\n",
    "    print('\\repoch [{}/{}], loss:{:.5f}'\n",
    "          .format(epoch, num_epochs-1, loss.data.item()), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([*model.encoder.c1.parameters(),\n",
    "                              *model.decoder.c3.parameters()], \n",
    "                             lr=1e-3, \n",
    "                             weight_decay=1e-6)\n",
    "\n",
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 2400, 3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [2978/3999], loss:0.00599"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "num_epochs=4000\n",
    "for epoch in range(num_epochs):\n",
    "    cur_loss = 0.0\n",
    "    for data in train_dl:\n",
    "        x, _ = data\n",
    "        x = x.reshape(-1, 8, 24).cuda()\n",
    "\n",
    "        output = torch.relu(model.encoder.c1(x))\n",
    "        output = model.decoder.c3(output)\n",
    "        loss = criterion(output, x)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        cur_loss += loss.item()\n",
    "    \n",
    "    losses += [cur_loss]\n",
    "    lr_scheduler.step()\n",
    "    print('\\repoch [{}/{}], loss:{:.5f}'\n",
    "          .format(epoch, num_epochs-1, loss.data.item()), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([*model.encoder.c2.parameters(),\n",
    "                              *model.decoder.c2.parameters()], lr=1e-3, weight_decay=1e-6)\n",
    "\n",
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 2400, 3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "num_epochs=10000\n",
    "for epoch in range(num_epochs):\n",
    "    cur_loss = 0.0\n",
    "    for data in train_dl:\n",
    "        x, _ = data\n",
    "        x = x.reshape(-1, 8, 24).cuda()\n",
    "\n",
    "        output = torch.relu(model.encoder.c1(x))\n",
    "        output = torch.relu(model.encoder.c2(output))\n",
    "        output = torch.relu(model.decoder.c2(output))\n",
    "        output = model.decoder.c3(output)\n",
    "        loss = criterion(output, x)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        cur_loss += loss.item()\n",
    "    \n",
    "    losses += [cur_loss]\n",
    "    lr_scheduler.step()\n",
    "    print('\\repoch [{}/{}], loss:{:.5f}'\n",
    "          .format(epoch, num_epochs-1, loss.data.item()), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "\n",
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 2400, 3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "num_epochs=10000\n",
    "for epoch in range(num_epochs):\n",
    "    cur_loss = 0.0\n",
    "    for data in train_dl:\n",
    "        x, _ = data\n",
    "        x = x.reshape(-1, 8, 24).cuda()\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, x)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        cur_loss += loss.item()\n",
    "    \n",
    "    losses += [cur_loss]\n",
    "    lr_scheduler.step()\n",
    "    print('\\repoch [{}/{}], loss:{:.5f}'\n",
    "          .format(epoch, num_epochs-1, loss.data.item()), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:clone_tf]",
   "language": "python",
   "name": "conda-env-clone_tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
