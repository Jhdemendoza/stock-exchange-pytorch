{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from scipy import optimize\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import datetime\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download_daily_data import my_list\n",
    "my_list = list(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supervised.utils import get_numeric_categoric, delta_dataframe_with_y_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfomed_combiner(df):\n",
    "    # Use only the ones worked well in autoencoder\n",
    "    transfomer = [\n",
    "        ('Data after min-max scaling',\n",
    "         MinMaxScaler()),\n",
    "        ('Data after max-abs scaling',\n",
    "         MaxAbsScaler()),\n",
    "        ('Data after quantile transformation (uniform pdf)',\n",
    "         QuantileTransformer(output_distribution='uniform')),\n",
    "        ('Data after sample-wise L2 normalizing',\n",
    "         Normalizer()),\n",
    "    ]\n",
    "\n",
    "    combined = FeatureUnion(transfomer)\n",
    "    _ = combined.fit(df)\n",
    "\n",
    "    return combined\n",
    "\n",
    "\n",
    "def get_input_target(ticker):\n",
    "    # messy code... \n",
    "    train_df_original, test_df_original, numeric_cols, categoric_cols = ohlc_train_df_test_df(ticker)\n",
    "    if train_df_original is None:\n",
    "        return None, None, None, None\n",
    "    \n",
    "    y_cols, not_interested = ohlc_get_y_cols(numeric_cols)\n",
    "    numeric_cols = list(sorted(set(numeric_cols) - set(y_cols) - set(not_interested)))    \n",
    "    \n",
    "    train_df, y_train = train_df_original[numeric_cols], train_df_original[y_cols]\n",
    "    test_df, y_test   = test_df_original[numeric_cols], test_df_original[y_cols]\n",
    "    y_train.drop(y_train.columns[2:], axis=1, inplace=True)\n",
    "    y_test.drop( y_test.columns[2:],  axis=1, inplace=True)\n",
    "\n",
    "    combined = get_transfomed_combiner(train_df)\n",
    "    \n",
    "    x_train_transformed = combined.transform(train_df).astype(np.float32)\n",
    "    x_test_transformed = combined.transform(test_df).astype(np.float32)\n",
    "\n",
    "    return x_train_transformed, x_test_transformed, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "ticker_dict = defaultdict(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ticker in my_list:\n",
    "    \n",
    "    if ticker in ticker_dict:\n",
    "        continue\n",
    "    \n",
    "    print('Processing: {}...'.format(ticker))\n",
    "    \n",
    "    try:\n",
    "        data_list = get_input_target(ticker)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "        \n",
    "    file_names = ('_x_train', '_x_test', \n",
    "                  '_y_train', '_y_test')\n",
    "    \n",
    "    if data_list[0] is not None:\n",
    "        \n",
    "        for file_name, data in zip(file_names, data_list):\n",
    "            f_name = 'data/ohlc_processed/' + ticker + file_name + '.pickle'\n",
    "            with open(f_name, 'wb') as handle:\n",
    "                pickle.dump(data, handle)\n",
    "        \n",
    "        ticker_dict[ticker] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
