{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from scipy import optimize\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_df_test_df(ticker):\n",
    "    \n",
    "    def concat_and_return_csvs(original_df, ticker_files):\n",
    "        for item in ticker_files[1:]:\n",
    "            this_df = pd.read_csv(data_path+item)\n",
    "            original_df = pd.concat([original_df, this_df])\n",
    "        return original_df\n",
    "    \n",
    "    data_path = 'data/daily_data/'\n",
    "    ticker_files = [item for item in os.listdir(data_path) if ticker in item.split('_')]\n",
    "    ticker_files.sort()\n",
    "    \n",
    "    split_idx = int(len(ticker_files) * 0.8)\n",
    "    train_ticker_files, test_ticker_files = ticker_files[:split_idx], ticker_files[split_idx:]\n",
    "\n",
    "    train_df = pd.read_csv(data_path+train_ticker_files[0])\n",
    "    train_df = concat_and_return_csvs(train_df, train_ticker_files)\n",
    "    \n",
    "    test_df = pd.read_csv(data_path+test_ticker_files[0])\n",
    "    test_df = concat_and_return_csvs(test_df, test_ticker_files)\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_minute_data(df):\n",
    "    cols = df.columns.tolist()\n",
    "    cols_to_drop = cols[:4] + ['label', 'changeOverTime', 'close', 'high', \n",
    "                               'low', 'marketAverage', 'marketClose', \n",
    "                               'marketOpen', 'volume', 'numberOfTrades', \n",
    "                               'notional', 'open', 'marketChangeOverTime']\n",
    "    df.drop(cols_to_drop, axis=1, inplace=True)\n",
    "    # necessary\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    idx_to_drop = df.index[df.marketNotional == 0.0]\n",
    "    df.drop(idx_to_drop, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    df.date = df.date.map(lambda x: datetime.datetime.strptime(str(x), '%Y%m%d'))\n",
    "    df['weekday'] = df.date.map(lambda x: str(x.weekday()))\n",
    "    df['month']   = df.date.map(lambda x: str(x.month))\n",
    "    \n",
    "    df.minute = df.minute.map(lambda x: datetime.datetime.strptime(x, '%H:%M'))\n",
    "    df['hour'] = df.minute.map(lambda x: str(x.hour))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numeric_categoric(df):\n",
    "    numeric_cols, categorical_cols = [], []\n",
    "\n",
    "    for col in df:\n",
    "        if np.issubdtype(df[col].dtype, np.number):\n",
    "            numeric_cols += [col]\n",
    "        else:\n",
    "            categorical_cols += [col]\n",
    "    \n",
    "    return numeric_cols, categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_dataframe(df, numeric_columns):\n",
    "    '''\n",
    "    log numerical columns, then return deltas\n",
    "    '''\n",
    "    \n",
    "    MAX_SHIFT_BACWARD, MAX_SHIFT_FORWARD = -20, 20\n",
    "    added_columns = []\n",
    "    for shift in [MAX_SHIFT_BACWARD, -10, -5, 3, 5, 10, MAX_SHIFT_FORWARD]:\n",
    "        for col in numeric_columns:\n",
    "            new_col_name = col + '_' + str(shift)\n",
    "            df[new_col_name] = df[col].shift(shift)\n",
    "            added_columns += [new_col_name]\n",
    "\n",
    "    df[numeric_columns+added_columns] = df[numeric_columns+added_columns].apply(np.log)\n",
    "    \n",
    "    # for lookbacks\n",
    "    for new_col in added_columns:\n",
    "        original_col, added_part = new_col.split('_')\n",
    "        df[new_col] = df[new_col] - df[original_col] if '-' in added_part else \\\n",
    "                      df[original_col] - df[new_col]\n",
    "\n",
    "    # for today\n",
    "    # This line is necessary\n",
    "    temp = df[numeric_columns] - df[numeric_columns].shift(1)\n",
    "    df[numeric_columns] = temp\n",
    "    \n",
    "    assert (df.index == np.arange(len(df))).all()\n",
    "    df.drop(df.index[list(range(MAX_SHIFT_FORWARD))], axis=0, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    #                            negative max_shift_back...\n",
    "    df.drop(index=list(range(len(df)+MAX_SHIFT_BACWARD, len(df))), inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframes(ticker):\n",
    "    train_df, test_df = train_df_test_df(ticker)\n",
    "    \n",
    "#     train_df, test_df = list(map(lambda x: get_processed_minute_data(x), \n",
    "#                                  (train_df, test_df)))\n",
    "    train_df = get_processed_minute_data(train_df)\n",
    "    test_df  = get_processed_minute_data(test_df)\n",
    "    \n",
    "    numeric_cols, categoric_cols = get_numeric_categoric(train_df)\n",
    "    # This is for the time being...\n",
    "    categoric_cols = ['weekday', 'month', 'hour']\n",
    "    \n",
    "    train_df = delta_dataframe(train_df, numeric_cols)\n",
    "    test_df  = delta_dataframe(test_df,  numeric_cols)\n",
    "    \n",
    "    # Re-evaluate column names from the deltas\n",
    "    numeric_cols, _ = get_numeric_categoric(train_df)\n",
    "    \n",
    "    return train_df, test_df, numeric_cols, categoric_cols\n",
    "\n",
    "def get_y_cols(numeric_cols):\n",
    "    price_cols      = [item for item in numeric_cols if '-' in item]\n",
    "    interested_cols = [item for item in price_cols if 'High' in item or 'Low' in item]\n",
    "    not_interested_cols = list(set(price_cols) - set(interested_cols))\n",
    "    return interested_cols, not_interested_cols\n",
    "\n",
    "# messy code... \n",
    "train_df_original, test_df_original, numeric_cols, categoric_cols = load_dataframes('cmg')\n",
    "y_cols, not_interested = get_y_cols(numeric_cols)\n",
    "numeric_cols = list(set(numeric_cols) - set(y_cols) - set(not_interested))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, y_train = train_df_original[numeric_cols], train_df_original[y_cols]\n",
    "test_df, y_test   = test_df_original[numeric_cols], test_df_original[y_cols]\n",
    "y_train.drop(y_train.columns[-2:], axis=1, inplace=True)\n",
    "y_test.drop(y_test.columns[-2:], axis=1, inplace=True)\n",
    "binary_y_train = (y_train>0.002).astype(np.int)\n",
    "binary_y_test  = (y_test>0.002 ).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only the ones worked well in autoencoder\n",
    "transfomer = [\n",
    "    ('Data after min-max scaling',\n",
    "        MinMaxScaler()),\n",
    "    ('Data after max-abs scaling',\n",
    "        MaxAbsScaler()),\n",
    "    ('Data after quantile transformation (uniform pdf)',\n",
    "        QuantileTransformer(output_distribution='uniform')),\n",
    "    ('Data after sample-wise L2 normalizing',\n",
    "        Normalizer()),\n",
    "]\n",
    "\n",
    "combined = FeatureUnion(transfomer)\n",
    "combined_fit = combined.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_transformed = combined.transform(train_df)\n",
    "x_test_transformed = combined.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8849, 100), (2272, 100))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_transformed.shape, x_test_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressor(nn.Module):\n",
    "    def __init__(self, input_size, final_output_size):\n",
    "        super(LogisticRegressor, self).__init__()\n",
    "\n",
    "        self.l1 = nn.Linear(input_size, 32)\n",
    "        self.l2 = nn.Linear(32, 16)\n",
    "#         self.l3 = nn.Linear(32, 16)\n",
    "        self.l4 = nn.Linear(16, final_output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.l1(x))\n",
    "        x = torch.tanh(self.l2(x))\n",
    "#         x = torch.tanh(self.l3(x))\n",
    "        return torch.sigmoid(self.l4(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TickerDataSimple(Dataset):\n",
    "    def __init__(self, ticker, x, y):\n",
    "        '''\n",
    "        :param ticker: string\n",
    "        :param x: np.array of x\n",
    "        :param y: np.array of y\n",
    "        '''\n",
    "        self.ticker = ticker\n",
    "        self.x = torch.FloatTensor(x)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_transformed = combined.transform(train_df)\n",
    "x_test_transformed = combined.transform(test_df)\n",
    "\n",
    "spy_dataset = TickerDataSimple('spy', x_train_transformed, \n",
    "                               torch.from_numpy(binary_y_train.values).float())\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_dl = DataLoader(spy_dataset, \n",
    "                      num_workers=1, \n",
    "                      batch_size=BATCH_SIZE)\n",
    "\n",
    "spy_testset = TickerDataSimple('spy', x_test_transformed, \n",
    "                               torch.from_numpy(binary_y_test.values).float())\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "test_dl = DataLoader(spy_testset, \n",
    "                      num_workers=1, \n",
    "                      batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_train_dl = iter(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 100]), torch.Size([64, 4]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter_train_dl)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(torch.nn.Module):\n",
    "    '''\n",
    "    Implement Focal Loss\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(CustomLoss,self).__init__()\n",
    "        \n",
    "    def forward(self, y_pred, y_target):\n",
    "        y_pred = y_pred.flatten()\n",
    "        y_target = y_target.flatten()\n",
    "        \n",
    "        def log_p(pred, target):\n",
    "            return -((1-pred) * torch.log2(pred) * target)\n",
    "        \n",
    "        return (log_p(y_pred, y_target) + log_p(1-y_pred, 1-y_target)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import clip_grad_norm_\n",
    "import torch.optim as optim\n",
    "\n",
    "# Each Data Points are 24 (6 * 4)\n",
    "# Transformer has 4 different ways\n",
    "model = LogisticRegressor(x_train_transformed.shape[1], y_train.shape[1])\n",
    "\n",
    "criterion = CustomLoss()\n",
    "# criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=1e-3, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ignite\n",
    "from ignite.metrics import BinaryAccuracy, Loss, Precision, Recall\n",
    "from ignite.engine import Events, \\\n",
    "                          create_supervised_trainer, \\\n",
    "                          create_supervised_evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as sk_metrics\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter_train_dl = iter(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.35151515151515145\n",
      "accuracy_score: 0.58203125\n",
      "roc_auc_score: 0.5517087192590228\n"
     ]
    }
   ],
   "source": [
    "# x, y = next(iter_train_dl)\n",
    "# _out = model(x)\n",
    "# _out = _out.flatten()\n",
    "# y    = y.flatten()\n",
    "# _zero_one = _out > 0.5\n",
    "# print('f1_score: {}'.format(sk_metrics.f1_score(_zero_one.detach().numpy(), y)))\n",
    "# print('accuracy_score: {}'.format(sk_metrics.accuracy_score(_zero_one, y)))\n",
    "# print('roc_auc_score: {}'.format(sk_metrics.roc_auc_score(y, _out.detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.metrics import Accuracy\n",
    "from functools import partial\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from ignite.metrics import EpochMetric\n",
    "\n",
    "\n",
    "def sk_metric_fn(y_preds, y_targets, sk_metrics, activation=None):\n",
    "    y_true = y_targets.flatten().numpy()\n",
    "    if activation is not None:\n",
    "        y_preds = activation(y_preds)\n",
    "    y_pred = y_preds.flatten().numpy()\n",
    "    return sk_metrics(y_true, y_pred)\n",
    "\n",
    "class ROC_AUC(EpochMetric):\n",
    "    def __init__(self, activation=None, output_transform=lambda x: x):\n",
    "        super(ROC_AUC, self).__init__(\n",
    "            partial(sk_metric_fn, \n",
    "                    sk_metrics=sk_metrics.roc_auc_score, \n",
    "                    activation=activation),\n",
    "            output_transform=output_transform)\n",
    "\n",
    "class F1_Score(EpochMetric):\n",
    "    def __init__(self, activation=None, output_transform=lambda x: x):\n",
    "        super(F1_Score, self).__init__(\n",
    "            partial(sk_metric_fn, \n",
    "                    sk_metrics=sk_metrics.f1_score, \n",
    "                    activation=activation),\n",
    "            output_transform=output_transform)\n",
    "\n",
    "class BinaryAccuracy(EpochMetric):\n",
    "    def __init__(self, activation=None, output_transform=lambda x: x):\n",
    "        super(BinaryAccuracy, self).__init__(\n",
    "            partial(sk_metric_fn, \n",
    "                    sk_metrics=sk_metrics.accuracy_score, \n",
    "                    activation=activation),\n",
    "            output_transform=output_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_one(y_preds):\n",
    "    return y_preds > 0.5\n",
    "\n",
    "def zero_one_transform(output):\n",
    "    return (zero_one(output[0])).long(), output[1].long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_loss = nn.modules.loss.BCELoss()\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion)\n",
    "evaluator = create_supervised_evaluator(\n",
    "    model,\n",
    "    metrics={\n",
    "        'accuracy': BinaryAccuracy(activation=zero_one),\n",
    "        'bce':      Loss(bce_loss),\n",
    "        'f1_score': F1_Score(activation=zero_one),\n",
    "        'roc_auc' : ROC_AUC(),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    evaluator.run(train_dl)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Training Results  - Epoch: {} Avg accuracy: {:.5f}, Avg BCE: {:.5f}, F1 Score: {:.5f}, ROC_AUC: {:.5f}\".format(trainer.state.epoch, \n",
    "                  metrics['accuracy'], \n",
    "                  metrics['bce'],\n",
    "                  metrics['f1_score'],\n",
    "                  metrics['roc_auc'],\n",
    "                 ))\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(test_dl)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results- Epoch: {} Avg accuracy: {:.5f}, Avg BCE: {:.5f}, F1 Score: {:.5f}, ROC_AUC: {:.5f}\".format(trainer.state.epoch, \n",
    "                  metrics['accuracy'], \n",
    "                  metrics['bce'],\n",
    "                  metrics['f1_score'],\n",
    "                  metrics['roc_auc'],\n",
    "                 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results  - Epoch: 1 Avg accuracy: 0.73932, Avg BCE: 0.58886, F1 Score: 0.00000, ROC_AUC: 0.55372\n",
      "Validation Results- Epoch: 1 Avg accuracy: 0.76585, Avg BCE: 0.57387, F1 Score: 0.00000, ROC_AUC: 0.54495\n",
      "Training Results  - Epoch: 2 Avg accuracy: 0.73932, Avg BCE: 0.58893, F1 Score: 0.00000, ROC_AUC: 0.56028\n",
      "Validation Results- Epoch: 2 Avg accuracy: 0.76585, Avg BCE: 0.57427, F1 Score: 0.00000, ROC_AUC: 0.54984\n",
      "Training Results  - Epoch: 3 Avg accuracy: 0.73932, Avg BCE: 0.58918, F1 Score: 0.00000, ROC_AUC: 0.56419\n",
      "Validation Results- Epoch: 3 Avg accuracy: 0.76585, Avg BCE: 0.57479, F1 Score: 0.00000, ROC_AUC: 0.55174\n",
      "Training Results  - Epoch: 4 Avg accuracy: 0.73932, Avg BCE: 0.58927, F1 Score: 0.00000, ROC_AUC: 0.56749\n",
      "Validation Results- Epoch: 4 Avg accuracy: 0.76585, Avg BCE: 0.57506, F1 Score: 0.00000, ROC_AUC: 0.55407\n",
      "Training Results  - Epoch: 5 Avg accuracy: 0.73932, Avg BCE: 0.58927, F1 Score: 0.00000, ROC_AUC: 0.57016\n",
      "Validation Results- Epoch: 5 Avg accuracy: 0.76585, Avg BCE: 0.57520, F1 Score: 0.00000, ROC_AUC: 0.55599\n",
      "Training Results  - Epoch: 6 Avg accuracy: 0.73932, Avg BCE: 0.58855, F1 Score: 0.00000, ROC_AUC: 0.57187\n",
      "Validation Results- Epoch: 6 Avg accuracy: 0.76585, Avg BCE: 0.57447, F1 Score: 0.00000, ROC_AUC: 0.55647\n",
      "Training Results  - Epoch: 7 Avg accuracy: 0.73932, Avg BCE: 0.58884, F1 Score: 0.00000, ROC_AUC: 0.57569\n",
      "Validation Results- Epoch: 7 Avg accuracy: 0.76585, Avg BCE: 0.57492, F1 Score: 0.00000, ROC_AUC: 0.55954\n",
      "Training Results  - Epoch: 8 Avg accuracy: 0.73938, Avg BCE: 0.58871, F1 Score: 0.00043, ROC_AUC: 0.57682\n",
      "Validation Results- Epoch: 8 Avg accuracy: 0.76585, Avg BCE: 0.57487, F1 Score: 0.00000, ROC_AUC: 0.56080\n",
      "Training Results  - Epoch: 9 Avg accuracy: 0.73941, Avg BCE: 0.58872, F1 Score: 0.00065, ROC_AUC: 0.57880\n",
      "Validation Results- Epoch: 9 Avg accuracy: 0.76585, Avg BCE: 0.57492, F1 Score: 0.00000, ROC_AUC: 0.56263\n",
      "Training Results  - Epoch: 10 Avg accuracy: 0.73946, Avg BCE: 0.58858, F1 Score: 0.00108, ROC_AUC: 0.58052\n",
      "Validation Results- Epoch: 10 Avg accuracy: 0.76596, Avg BCE: 0.57480, F1 Score: 0.00094, ROC_AUC: 0.56402\n",
      "Training Results  - Epoch: 11 Avg accuracy: 0.73972, Avg BCE: 0.58822, F1 Score: 0.00368, ROC_AUC: 0.58229\n",
      "Validation Results- Epoch: 11 Avg accuracy: 0.76596, Avg BCE: 0.57442, F1 Score: 0.00188, ROC_AUC: 0.56590\n",
      "Training Results  - Epoch: 12 Avg accuracy: 0.73977, Avg BCE: 0.58797, F1 Score: 0.00540, ROC_AUC: 0.58387\n",
      "Validation Results- Epoch: 12 Avg accuracy: 0.76596, Avg BCE: 0.57419, F1 Score: 0.00375, ROC_AUC: 0.56700\n",
      "Training Results  - Epoch: 13 Avg accuracy: 0.73980, Avg BCE: 0.58753, F1 Score: 0.00540, ROC_AUC: 0.58512\n",
      "Validation Results- Epoch: 13 Avg accuracy: 0.76585, Avg BCE: 0.57374, F1 Score: 0.00468, ROC_AUC: 0.56733\n",
      "Training Results  - Epoch: 14 Avg accuracy: 0.73980, Avg BCE: 0.58710, F1 Score: 0.00604, ROC_AUC: 0.58649\n",
      "Validation Results- Epoch: 14 Avg accuracy: 0.76585, Avg BCE: 0.57331, F1 Score: 0.00561, ROC_AUC: 0.56809\n",
      "Training Results  - Epoch: 15 Avg accuracy: 0.73983, Avg BCE: 0.58664, F1 Score: 0.00626, ROC_AUC: 0.58768\n",
      "Validation Results- Epoch: 15 Avg accuracy: 0.76596, Avg BCE: 0.57287, F1 Score: 0.00654, ROC_AUC: 0.56821\n",
      "Training Results  - Epoch: 16 Avg accuracy: 0.74003, Avg BCE: 0.58612, F1 Score: 0.00776, ROC_AUC: 0.58875\n",
      "Validation Results- Epoch: 16 Avg accuracy: 0.76596, Avg BCE: 0.57233, F1 Score: 0.00654, ROC_AUC: 0.56828\n",
      "Training Results  - Epoch: 17 Avg accuracy: 0.74006, Avg BCE: 0.58566, F1 Score: 0.00883, ROC_AUC: 0.58984\n",
      "Validation Results- Epoch: 17 Avg accuracy: 0.76596, Avg BCE: 0.57193, F1 Score: 0.00654, ROC_AUC: 0.56807\n",
      "Training Results  - Epoch: 18 Avg accuracy: 0.74011, Avg BCE: 0.58518, F1 Score: 0.00969, ROC_AUC: 0.59058\n",
      "Validation Results- Epoch: 18 Avg accuracy: 0.76618, Avg BCE: 0.57152, F1 Score: 0.00840, ROC_AUC: 0.56771\n",
      "Training Results  - Epoch: 19 Avg accuracy: 0.74025, Avg BCE: 0.58469, F1 Score: 0.01097, ROC_AUC: 0.59141\n",
      "Validation Results- Epoch: 19 Avg accuracy: 0.76640, Avg BCE: 0.57110, F1 Score: 0.01210, ROC_AUC: 0.56768\n",
      "Training Results  - Epoch: 20 Avg accuracy: 0.74042, Avg BCE: 0.58420, F1 Score: 0.01247, ROC_AUC: 0.59252\n",
      "Validation Results- Epoch: 20 Avg accuracy: 0.76629, Avg BCE: 0.57070, F1 Score: 0.01209, ROC_AUC: 0.56808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ignite.engine.engine.State at 0x7f650f13c8d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.run(train_dl, max_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:clone_tf]",
   "language": "python",
   "name": "conda-env-clone_tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
